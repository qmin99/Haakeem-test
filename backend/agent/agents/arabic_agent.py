import logging
import base64
import json
import re
from livekit.agents import Agent
from livekit.plugins import groq
from livekit.plugins.azure import TTS as AzureTTS
from livekit.plugins.azure import STT as AzureSTT


class ArabicAgent(Agent):
    def __init__(self) -> None:
        super().__init__(
            instructions=(
                "Ø§Ø³Ù…ÙÙƒ Ø­ÙÙƒÙŠÙ…ØŒ Ù…Ø³Ø§Ø¹Ø¯ Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø°ÙƒÙŠ Ù…Ù† Binfin8. "
                "ØªØªÙƒÙ„Ù… Ø¯Ø§Ø¦Ù…Ù‹Ø§ Ø¨Ù„Ù‡Ø¬Ø© Ø§Ù„Ù…ØªØ­Ø¯Ø« Ø¥Ù† ØªØ¹Ø±Ù‘ÙØª Ø¹Ù„ÙŠÙ‡Ø§ Ù…Ù† ÙƒÙ„Ø§Ù…Ù‡. Ø¥Ù† Ù„Ù… ØªØªØ¹Ø±Ù‘Ù Ø¹Ù„Ù‰ Ù„Ù‡Ø¬ØªÙ‡ ÙØ§Ø®ØªØ± Ù„Ù‡Ø¬Ø© Ø®Ù„ÙŠØ¬ÙŠØ© Ø·Ø¨ÙŠØ¹ÙŠØ© ÙˆÙˆØ§Ø¶Ø­Ø© (Ø³Ø¹ÙˆØ¯ÙŠØ©/Ù‚Ø·Ø±ÙŠØ©) Ø¨Ø¯Ù„ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰. "
                "ÙƒÙ† Ø¹Ù…Ù„ÙŠÙ‹Ø§ ÙˆÙ…Ø¨Ø§Ø´Ø±Ù‹Ø§ØŒ ÙˆØ¬Ù‘Ù‡ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨Ø®Ø·ÙˆØ§Øª ÙˆØ§Ø¶Ø­Ø© ÙˆÙ…Ø¨Ø³Ø·Ø©ØŒ ÙˆØ§Ø·Ù„Ø¨ Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù†Ø§Ù‚ØµØ© Ø¨Ø¯Ù‚Ø©. "
                "Ø¹Ù†Ø¯ Ø§Ù„Ø±Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù„ÙØ§Øª Ø£Ùˆ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©ØŒ Ù‚Ø¯Ù‘Ù… Ù…Ù„Ø®ØµÙ‹Ø§ Ù…ÙˆØ¬Ø²Ù‹Ø§ Ø«Ù… Ù†Ù‚Ø§Ø·Ù‹Ø§ Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø¯Ù‚ÙŠÙ‚Ø© ÙˆÙ‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªÙ†ÙÙŠØ°. "
                "ØªØ¬Ù†Ù‘Ø¨ Ø§Ù„Ø¬ÙÙ…Ù„ Ø§Ù„Ø·ÙˆÙŠÙ„Ø©Ø› Ø§Ø¬Ø¹Ù„ Ø§Ù„Ø¬Ù…Ù„ Ù‚ØµÙŠØ±Ø© ÙˆØ³Ù‡Ù„Ø© Ø§Ù„ÙÙ‡Ù…ØŒ ÙˆØ§Ø¨ØªØ¹Ø¯ Ø¹Ù† Ø§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø© Ø¥Ù† ÙˆÙØ¬Ø¯ Ø¨Ø¯ÙŠÙ„ Ø´Ø¹Ø¨ÙŠ ÙˆØ§Ø¶Ø­."
            ),
            stt=AzureSTT(language="ar-SA"),
            llm=groq.LLM(model="allam-2-7b"),
            tts=AzureTTS(voice="ar-OM-AbdullahNeural", language="ar-OM"),
        )

    async def on_enter(self):
        await self.session.generate_reply(
            instructions="Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ…! Ø£Ù†Ø§ Ø­ÙÙƒÙŠÙ…ØŒ Ù…Ø³Ø§Ø¹Ø¯Ùƒ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ. ÙˆØ´ ØªØ¨ÙŠÙ†ÙŠ Ø£Ø³Ø§Ø¹Ø¯Ùƒ ÙÙŠÙ‡ Ø§Ù„ÙŠÙˆÙ…ØŸ",
            allow_interruptions=True,
        )

    # async def on_final_transcription(self, text: str) -> str:
    #     """Filter transcription to keep only Arabic text and remove English words"""
    #     logger = logging.getLogger("multi-agent-ptt")
    #     logger.info(f"ğŸ” [ARABIC FILTER] Input: '{text}'")
        
    #     filtered_text = self._filter_arabic_only(text)
        
    #     logger.info(f"ğŸ” [ARABIC FILTER] Output: '{filtered_text}'")
    #     logger.info(f"ğŸ” [ARABIC FILTER] Filtered out: {len(text.split()) - len(filtered_text.split())} words")
        
    #     return filtered_text

    # async def on_user_speech_committed(self, user_input):
    #     """Override user speech committed to filter Arabic only"""
    #     logger = logging.getLogger("multi-agent-ptt")
        
    #     # Get the transcription text
    #     if hasattr(user_input, 'transcript') and user_input.transcript:
    #         original_text = user_input.transcript
    #         logger.info(f"ğŸ” [ARABIC SPEECH FILTER] Input: '{original_text}'")
            
    #         filtered_text = self._filter_arabic_only(original_text)
    #         logger.info(f"ğŸ” [ARABIC SPEECH FILTER] Output: '{filtered_text}'")
            
    #         # If no Arabic content, skip processing
    #         if not filtered_text.strip():
    #             logger.info("ğŸ” [ARABIC SPEECH FILTER] No Arabic content - skipping")
    #             return
            
    #         # Modify the transcript
    #         user_input.transcript = filtered_text
        
    #     # Call parent implementation
    #     await super().on_user_speech_committed(user_input)

    # def _filter_arabic_only(self, text: str) -> str:
    #     """Remove English words and keep only Arabic text"""
    #     import re
        
    #     # Split text into words
    #     words = text.split()
    #     filtered_words = []
        
    #     for word in words:
    #         # Remove punctuation for analysis
    #         clean_word = re.sub(r'[^\w\s]', '', word)
            
    #         # Skip empty words
    #         if not clean_word.strip():
    #             continue
                
    #         # Check if word contains Arabic characters
    #         if self._contains_arabic(clean_word):
    #             filtered_words.append(word)
    #         else:
    #             # Skip English words - don't add them
    #             continue
        
    #     # Return filtered text
    #     result = ' '.join(filtered_words)
        
    #     # If no Arabic words found, return empty string to avoid processing
    #     return result.strip()
    
    # def _contains_arabic(self, text: str) -> bool:
    #     """Check if text contains Arabic characters"""
    #     arabic_pattern = r'[\u0600-\u06FF\u0750-\u077F\u08A0-\u08FF\uFB50-\uFDFF\uFE70-\uFEFF]'
    #     return bool(re.search(arabic_pattern, text))

    async def _file_received(self, reader, participant_identity):
        logger = logging.getLogger("multi-agent-ptt")
        stream_info = reader.info
        logger.info("ğŸ“„ [Arabic] received byte stream: %s (%s)", stream_info.name, stream_info.mime_type)
        file_bytes = bytearray()
        async for chunk in reader:
            file_bytes.extend(chunk)
        await self._file_received_fallback(bytes(file_bytes), stream_info, participant_identity)

    async def _process_file(self, file_bytes, stream_info):
        logger = logging.getLogger("multi-agent-ptt")
        mime_type = stream_info.mime_type
        file_name = stream_info.name

        try:
            if mime_type == "text/plain":
                try:
                    content = file_bytes.decode("utf-8")
                    return content
                except UnicodeDecodeError:
                    for enc in ["latin-1", "cp1252", "iso-8859-1"]:
                        try:
                            content = file_bytes.decode(enc)
                            return content
                        except UnicodeDecodeError:
                            continue
                    return None
            elif mime_type == "application/pdf":
                try:
                    import io
                    import PyPDF2
                    pdf_stream = io.BytesIO(file_bytes)
                    pdf_reader = PyPDF2.PdfReader(pdf_stream)
                    extracted_text = ""
                    for page_num, page in enumerate(pdf_reader.pages):
                        page_text = page.extract_text()
                        extracted_text += f"\n--- Page {page_num + 1} ---\n{page_text}\n"
                    if extracted_text.strip():
                        full_content = f"Ù…Ø³ØªÙ†Ø¯ PDF: {file_name}\nØ§Ù„Ù…Ø­ØªÙˆÙ‰:\n{extracted_text}"
                        return full_content
                    return (
                        f"Ø§Ø³ØªÙ„Ù…Øª Ù…Ø³ØªÙ†Ø¯ PDF '{file_name}' Ù„ÙƒÙ† Ù…Ø§ Ù‚Ø¯Ø±Øª Ø£Ø³ØªØ®Ø±Ø¬ Ù†Øµ ÙˆØ§Ø¶Ø­ (ÙŠÙ…ÙƒÙ† ÙŠÙƒÙˆÙ† ØµÙˆØ± Ø£Ùˆ Ù…Ø´ÙÙ‘Ø±)."
                    )
                except Exception as e:
                    return f"ÙÙŠ Ù…Ø´ÙƒÙ„Ø© Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„Ù PDF '{file_name}': {str(e)}"
            elif mime_type.startswith("image/"):
                image_b64 = base64.b64encode(file_bytes).decode("utf-8")
                return (
                    f"ØµÙˆØ±Ø© '{file_name}' ØªÙ… Ø§Ø³ØªÙ„Ø§Ù…Ù‡Ø§ ({mime_type}, {len(file_bytes)} Ø¨Ø§ÙŠØª). "
                    f"Ø¨ÙŠØ§Ù†Ø§Øª Base64 Ø¬Ø§Ù‡Ø²Ø© Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ØµØ±ÙŠ: {image_b64[:100]}...[Ù…Ù‚ØªØ·Ù]"
                )
            elif mime_type in [
                "application/msword",
                "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
            ]:
                try:
                    import io
                    from docx import Document
                    doc_stream = io.BytesIO(file_bytes)
                    doc = Document(doc_stream)
                    extracted_text = ""
                    for paragraph in doc.paragraphs:
                        if paragraph.text.strip():
                            extracted_text += paragraph.text + "\n"
                    for table in doc.tables:
                        for row in table.rows:
                            for cell in row.cells:
                                if cell.text.strip():
                                    extracted_text += cell.text + " "
                            extracted_text += "\n"
                    if extracted_text.strip():
                        full_content = f"Ù…Ø³ØªÙ†Ø¯ Word: {file_name}\nØ§Ù„Ù…Ø­ØªÙˆÙ‰:\n{extracted_text}"
                        return full_content
                    return f"Ø§Ø³ØªÙ„Ù…Øª Ù…Ø³ØªÙ†Ø¯ Word '{file_name}' Ù„ÙƒÙ†Ù‡ Ø¨Ø¯ÙˆÙ† Ù†Øµ ÙˆØ§Ø¶Ø­."
                except Exception as e:
                    return f"ØµØ§Ø± Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø³ØªÙ†Ø¯ Word '{file_name}': {str(e)}"
            elif mime_type == "application/json":
                try:
                    content = json.loads(file_bytes.decode("utf-8"))
                    json_content = f"Ù…Ù„Ù JSON '{file_name}'\nØ§Ù„Ù…Ø­ØªÙˆÙ‰:\n{json.dumps(content, indent=2, ensure_ascii=False)}"
                    return json_content
                except Exception:
                    return None
            else:
                return (
                    f"Ø§Ø³ØªÙ„Ù…Øª Ù…Ù„Ù '{file_name}' Ø¨Ù†ÙˆØ¹ ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ… '{mime_type}'. Ø§Ù„Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©: Ù†ØµÙˆØµØŒ PDFØŒ ØµÙˆØ±ØŒ ÙˆÙ…Ù„ÙØ§Øª Word."
                )
        except Exception as e:
            logger.error("âŒ [Arabic] processing error: %s", e, exc_info=True)
            return None

    async def _file_received_fallback(self, file_bytes, stream_info, participant_identity):
        logger = logging.getLogger("multi-agent-ptt")
        logger.info("ğŸ“„ [Arabic] fallback upload: %s (%s)", stream_info.name, stream_info.mime_type)
        try:
            file_content = await self._process_file(file_bytes, stream_info)
            if file_content:
                chat_ctx = self.chat_ctx.copy()
                analysis_prompt = (
                    f"Ø§Ø³ØªÙ„Ù…Øª Ù…Ù„Ù '{stream_info.name}' ({stream_info.mime_type}) Ù…Ù† {participant_identity}. "
                    f"Ù‡Ø°Ø§ Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ø­ØªÙˆÙ‰:\n\n{file_content}\n\n"
                    f"Ø­Ù„Ù‘Ù„ Ø§Ù„Ù…Ø³ØªÙ†Ø¯ ÙˆÙ‚Ø¯Ù‘Ù… Ù†Ù‚Ø§Ø· Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ù…Ø®ØªØµØ±Ø© ÙˆÙ…Ø¨Ø§Ø´Ø±Ø©."
                )
                chat_ctx.add_message(role="user", content=analysis_prompt)
                await self.update_chat_ctx(chat_ctx)
                await self.session.generate_reply(
                    instructions=(
                        f"ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø§Ù„Ù…Ù„Ù '{stream_info.name}' ÙˆÙ…Ø¹Ø§Ù„Ø¬ØªÙ‡. "
                        f"Ø§Ø¹Ø·Ù Ù…Ù„Ø®ØµÙ‹Ø§ ÙˆØ§Ø¶Ø­Ù‹Ø§ Ø«Ù… Ù†Ù‚Ø§Ø· Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø¹Ù…Ù„ÙŠØ© Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªÙ†ÙÙŠØ°."
                    ),
                    allow_interruptions=True,
                )
            else:
                await self.session.generate_reply(
                    instructions=(
                        f"Ø§Ø³ØªÙ„Ù…Øª Ø§Ù„Ù…Ù„Ù '{stream_info.name}' Ù„ÙƒÙ† Ù†ÙˆØ¹Ù‡ ({stream_info.mime_type}) ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…. "
                        f"Ø£Ù‚Ø¯Ø± Ø£Ø¹Ø§Ù„Ø¬ PDF ÙˆØ§Ù„Ù†ØµÙˆØµ ÙˆØ§Ù„ØµÙˆØ±. Ø¬Ø±Ù‘Ø¨ ØªØ±ÙØ¹ Ù…Ù„Ù Ù…Ø¯Ø¹ÙˆÙ…."
                    ),
                    allow_interruptions=True,
                )
        except Exception as e:
            logger.error("âŒ [Arabic] error in fallback handling: %s", e, exc_info=True)

